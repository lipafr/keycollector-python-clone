#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ WordstatParser —Å KeywordManager
"""

def add_wordstat_integration_method():
    """
    –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤ –∫–ª–∞—Å—Å WordstatParser
    """
    
    method_code = '''
def add_to_manager_fixed(self, keyword_manager, 
                        min_frequency: int = 0,
                        exclude_patterns: list = None,
                        max_keywords: int = None) -> dict:
    """
    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ KeywordManager
    
    Args:
        keyword_manager: –û–±—ä–µ–∫—Ç KeywordManager
        min_frequency: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)
        exclude_patterns: –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, ['snowrunner'])
        max_keywords: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (None = –≤—Å–µ)
    
    Returns:
        dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    """
    if exclude_patterns is None:
        exclude_patterns = []
    
    stats = {
        'total': len(self.keywords),
        'added': 0,
        'skipped': 0,
        'duplicates': 0,
        'errors': 0
    }
    
    print(f"üöÄ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ KeywordManager...")
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"   - –í—Å–µ–≥–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {stats['total']}")
    print(f"   - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {min_frequency}")
    print(f"   - –ò—Å–∫–ª—é—á–µ–Ω–∏—è: {exclude_patterns}")
    print(f"   - –õ–∏–º–∏—Ç: {max_keywords or '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}")
    
    for i, keyword_data in enumerate(self.keywords):
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            keyword_text = keyword_data.get('keyword', '').strip()
            frequency = keyword_data.get('frequency', 0)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ
            if not keyword_text:
                stats['skipped'] += 1
                continue
            
            # –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Å—Ç–æ—Ç–µ
            if frequency < min_frequency:
                stats['skipped'] += 1
                continue
            
            # –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è–º
            skip_keyword = False
            for pattern in exclude_patterns:
                if pattern.lower() in keyword_text.lower():
                    skip_keyword = True
                    break
            
            if skip_keyword:
                stats['skipped'] += 1
                continue
            
            # –õ–∏–º–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
            if max_keywords and stats['added'] >= max_keywords:
                break
            
            # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û –¥–æ–±–∞–≤–ª—è–µ–º —Å –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            success = keyword_manager.add_keyword(
                keyword=keyword_text,
                frequency=frequency,  # ‚Üê –ü–µ—Ä–µ–¥–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å!
                cpc=0.0
            )
            
            if success:
                stats['added'] += 1
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è
                if stats['added'] <= 10:
                    print(f"   ‚úÖ '{keyword_text}' ‚Üí {frequency:,} –∑–∞–ø—Ä–æ—Å–æ–≤")
                elif stats['added'] % 50 == 0:
                    print(f"   üìà –î–æ–±–∞–≤–ª–µ–Ω–æ: {stats['added']}...")
            else:
                stats['duplicates'] += 1
                
        except Exception as e:
            stats['errors'] += 1
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è:")
    print(f"   üìÅ –í—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ: {stats['total']}")
    print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {stats['added']}")
    print(f"   ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
    print(f"   üîÑ –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['duplicates']}")
    print(f"   ‚ùå –û—à–∏–±–æ–∫: {stats['errors']}")
    
    success_rate = (stats['added'] / stats['total']) * 100 if stats['total'] > 0 else 0
    print(f"   üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1f}%")
    
    return stats
    '''
    
    return method_code


def create_fixed_test():
    """–°–æ–∑–¥–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç"""
    
    test_code = '''
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –¢–ï–°–¢ - –¥–æ–±–∞–≤–ª—è–µ—Ç –≤—Å–µ 352 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞
"""

from wordstat_parser import WordstatParser
from keyword_manager import KeywordManager

# –î–æ–±–∞–≤—å—Ç–µ –º–µ—Ç–æ–¥ add_to_manager_fixed –≤ WordstatParser (–∫–æ–¥ –≤—ã—à–µ)
# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥:

def test_fixed_integration():
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    
    print("üß™ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –¢–ï–°–¢ WordstatParser + KeywordManager")
    print("="*70)
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    parser = WordstatParser()
    parser.parse_file("data/input/–≥–µ–æ–ª–æ–≥–æ—Ä–∞–∑–≤–µ–¥–∫–∞ wordstat.xlsx")
    
    print(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ WordStat: {len(parser.keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    
    # 2. –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä
    manager = KeywordManager()
    
    # 3. –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞–ø—Ä—è–º—É—é
    print(f"\\nüöÄ –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞...")
    
    added = 0
    errors = 0
    
    for keyword_data in parser.keywords:
        try:
            keyword_text = keyword_data.get('keyword', '').strip()
            frequency = keyword_data.get('frequency', 0)
            
            if not keyword_text:
                continue
            
            # ‚úÖ –ö–õ–Æ–ß–ï–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø–µ—Ä–µ–¥–∞–µ–º frequency –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            success = manager.add_keyword(
                keyword=keyword_text,
                frequency=frequency,  # ‚Üê –†–µ–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –∏–∑ WordStat
                cpc=0.0
            )
            
            if success:
                added += 1
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                if added <= 5:
                    print(f"   ‚úÖ '{keyword_text}' ‚Üí freq: {frequency}")
            
        except Exception as e:
            errors += 1
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    total_in_manager = len(manager.keywords)
    
    print(f"\\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   üìÅ –í WordStat —Ñ–∞–π–ª–µ: {len(parser.keywords)}")
    print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {added}")
    print(f"   üéØ –í –º–µ–Ω–µ–¥–∂–µ—Ä–µ: {total_in_manager}")
    print(f"   ‚ùå –û—à–∏–±–æ–∫: {errors}")
    
    # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å
    print(f"\\nüèÜ –¢–æ–ø-5 –ø–æ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏:")
    sorted_kw = sorted(manager.keywords, key=lambda x: x.frequency, reverse=True)
    
    for i, kw in enumerate(sorted_kw[:5], 1):
        print(f"   {i}. '{kw.text}' ‚Üí {kw.frequency:,} –∑–∞–ø—Ä–æ—Å–æ–≤")
    
    # 6. –ò—Ç–æ–≥–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    highest_freq = sorted_kw[0].frequency if sorted_kw else 0
    
    if total_in_manager >= 350 and highest_freq > 10000:
        print(f"\\nüéâ –ü–û–õ–ù–´–ô –£–°–ü–ï–•!")
        print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {total_in_manager} –∏–∑ {len(parser.keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
        print(f"   ‚úÖ –ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è: max = {highest_freq:,}")
        return True
    else:
        print(f"\\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–´:")
        if total_in_manager < 350:
            print(f"   ‚ùå –ú–∞–ª–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {total_in_manager} < 350")
        if highest_freq <= 10000:
            print(f"   ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å: {highest_freq}")
        
        print(f"\\nüîß –ü–†–û–í–ï–†–¨–¢–ï:")
        print(f"   1. –ö–ª–∞—Å—Å Keyword –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä frequency?")
        print(f"   2. WordstatParser –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–∞—Ä—Å–∏—Ç —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å?")
        print(f"   3. –ù–µ—Ç –ª–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –≤ add_keyword?")
        
        return False

if __name__ == "__main__":
    success = test_fixed_integration()
    
    if success:
        print(f"\\nüéä –í–°–Å –ò–°–ü–†–ê–í–õ–ï–ù–û! –¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤—Å–µ 352 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞!")
    '''
    
    return test_code


if __name__ == "__main__":
    print("üõ†Ô∏è –ö–æ–¥ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è WordstatParser:")
    print("="*50)
    print(add_wordstat_integration_method())
    
    print("\\n" + "="*50)
    print("üìã –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫: test_fixed_wordstat.py")
    print("="*50)
    print(create_fixed_test())